Operations
==========

Operations Implementations are subclasses of
:class:`dffml.df.base.OperationImplementation`, they are functions or classes
which could do anything, make HTTP requests, do inference, etc.

They don't necessarily have to be written in Python. Although DFFML isn't quite
to the point where it can use operations written in other languages yet, it's on
the roadmap.

.. _plugin_operation_dffml:

dffml
-----

.. code-block:: console

    pip install dffml


.. _plugin_operation_dffml_AcceptUserInput:

AcceptUserInput
~~~~~~~~~~~~~~~

*Official*

Accept input from stdin using python input()

Parameters
++++++++++
inputs : dict
    A dictionary with a key and empty list as value.

Returns
+++++++
dict
    A dictionary containing user input.

Examples
++++++++

The following example shows how to use AcceptUserInput.

>>> dataflow = DataFlow.auto(AcceptUserInput, GetSingle)
>>> dataflow.seed.append(
...     Input(
...         value=[AcceptUserInput.op.outputs["InputData"].name],
...         definition=GetSingle.op.inputs["spec"]
...     )
... )
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(dataflow, {"input":[]}):
...         print(results)
>>>
>>> asyncio.run(main())
{'UserInput': {'data': 'Data flow is awesome'}}

**Stage: processing**



**Outputs**

- InputData: UserInput(type: str)

.. _plugin_operation_dffml_associate:

associate
~~~~~~~~~

*Official*

No description

**Stage: output**



**Inputs**

- spec: associate_spec(type: List[str])

**Outputs**

- output: associate_output(type: Dict[str, Any])

.. _plugin_operation_dffml_dffml_dataflow_run:

dffml.dataflow.run
~~~~~~~~~~~~~~~~~~

*Official*

Starts a subflow ``self.config.dataflow`` and adds ``inputs`` in it.

Parameters
++++++++++
inputs : dict
    The inputs to add to the subflow. These should be a key value mapping of
    the context string to the inputs which should be seeded for that context
    string.

Returns
+++++++
dict
    Maps context strings in inputs to output after running through dataflow.

Examples
++++++++

The following shows how to use run dataflow in its default behavior.

>>> URL = Definition(name="URL", primitive="string")
>>>
>>> subflow = DataFlow.auto(GetSingle)
>>> subflow.definitions[URL.name] = URL
>>> subflow.seed.append(
...     Input(
...         value=[URL.name],
...         definition=GetSingle.op.inputs["spec"]
...     )
... )
>>>
>>> dataflow = DataFlow.auto(run_dataflow, GetSingle)
>>> dataflow.configs[run_dataflow.imp.op.name] = RunDataFlowConfig(subflow)
>>> dataflow.seed.append(
...     Input(
...         value=[run_dataflow.imp.op.outputs["results"].name],
...         definition=GetSingle.op.inputs["spec"]
...     )
... )
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(dataflow, {
...         "run_subflow": [
...             Input(
...                 value={
...                     "dffml": [
...                         {
...                             "value": "https://github.com/intel/dffml",
...                             "definition": URL.name
...                         }
...                     ]
...                 },
...                 definition=run_dataflow.imp.op.inputs["inputs"]
...             )
...         ]
...     }):
...         print(results)
>>>
>>> asyncio.run(main())
{'flow_results': {'dffml': {'URL': 'https://github.com/intel/dffml'}}}

The following shows how to use run dataflow with custom inputs and outputs.
This allows you to run a subflow as if it were an opertion.

>>> URL = Definition(name="URL", primitive="string")
>>>
>>> @op(
...     inputs={"url": URL},
...     outputs={"last": Definition("last_element_in_path", primitive="string")},
... )
... def last_path(url):
...     return {"last": url.split("/")[-1]}
>>>
>>> subflow = DataFlow.auto(last_path, GetSingle)
>>> subflow.seed.append(
...     Input(
...         value=[last_path.op.outputs["last"].name],
...         definition=GetSingle.op.inputs["spec"],
...     )
... )
>>>
>>> dataflow = DataFlow.auto(run_dataflow, GetSingle)
>>> dataflow.operations[run_dataflow.op.name] = run_dataflow.op._replace(
...     inputs={"URL": URL},
...     outputs={last_path.op.outputs["last"].name: last_path.op.outputs["last"]},
...     expand=[],
... )
>>> dataflow.configs[run_dataflow.op.name] = RunDataFlowConfig(subflow)
>>> dataflow.seed.append(
...     Input(
...         value=[last_path.op.outputs["last"].name],
...         definition=GetSingle.op.inputs["spec"],
...     )
... )
>>> dataflow.update(auto_flow=True)
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(
...         dataflow,
...         {
...             "run_subflow": [
...                 Input(value="https://github.com/intel/dffml", definition=URL)
...             ]
...         },
...     ):
...         print(results)
>>>
>>> asyncio.run(main())
{'last_element_in_path': 'dffml'}

**Stage: processing**



**Inputs**

- inputs: flow_inputs(type: Dict[str,Any])

**Outputs**

- results: flow_results(type: Dict[str,Any])

**Args**

- dataflow: DataFlow

.. _plugin_operation_dffml_dffml_mapping_create:

dffml.mapping.create
~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- key: key(type: str)
- value: value(type: generic)

**Outputs**

- mapping: mapping(type: map)

.. _plugin_operation_dffml_dffml_mapping_extract:

dffml.mapping.extract
~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- mapping: mapping(type: map)
- traverse: mapping_traverse(type: List[str])

**Outputs**

- value: value(type: generic)

.. _plugin_operation_dffml_dffml_model_predict:

dffml.model.predict
~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- features: record_features(type: Dict[str, Any])

**Outputs**

- prediction: model_predictions(type: Dict[str, Any])

**Args**

- model: Entrypoint

.. _plugin_operation_dffml_get_multi:

get_multi
~~~~~~~~~

*Official*

Output operation to get all Inputs matching given definitions.

Parameters
++++++++++
spec : list
    List of definition names. Any Inputs with matching definition will be
    returned.

Returns
+++++++
dict
    Maps definition names to all the Inputs of that definition

Examples
++++++++

The following shows how to grab all Inputs with the URL definition. If we
had we run an operation which output a URL, that output URL would have also
been returned to us.

>>> URL = Definition(name="URL", primitive="string")
>>>
>>> dataflow = DataFlow.auto(GetMulti)
>>> dataflow.seed.append(
...     Input(
...         value=[URL.name],
...         definition=GetMulti.op.inputs["spec"]
...     )
... )
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(dataflow, [
...         Input(
...             value="https://github.com/intel/dffml",
...             definition=URL
...         ),
...         Input(
...             value="https://github.com/intel/cve-bin-tool",
...             definition=URL
...         )
...     ]):
...         print(results)
...
>>> asyncio.run(main())
{'URL': ['https://github.com/intel/dffml', 'https://github.com/intel/cve-bin-tool']}

**Stage: output**



**Inputs**

- spec: get_n_spec(type: array)

**Outputs**

- output: get_n_output(type: map)

.. _plugin_operation_dffml_get_single:

get_single
~~~~~~~~~~

*Official*

Output operation to get a single Input for each definition given.

Parameters
++++++++++
spec : list
    List of definition names. An Input with matching definition will be
    returned.

Returns
+++++++
dict
    Maps definition names to an Input of that definition

Examples
++++++++

The following shows how to grab an Inputs with the URL definition. If we
had we run an operation which output a URL, that output URL could have also
been returned to us.

>>> URL = Definition(name="URL", primitive="string")
>>>
>>> dataflow = DataFlow.auto(GetSingle)
>>> dataflow.seed.append(
...     Input(
...         value=[URL.name],
...         definition=GetSingle.op.inputs["spec"]
...     )
... )
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(dataflow, [
...         Input(
...             value="https://github.com/intel/dffml",
...             definition=URL
...         )
...     ]):
...         print(results)
...
>>> asyncio.run(main())
{'URL': 'https://github.com/intel/dffml'}

**Stage: output**



**Inputs**

- spec: get_single_spec(type: array)

**Outputs**

- output: get_single_output(type: map)

.. _plugin_operation_dffml_group_by:

group_by
~~~~~~~~

*Official*

No description

**Stage: output**



**Inputs**

- spec: group_by_spec(type: Dict[str, Any])

**Outputs**

- output: group_by_output(type: Dict[str, List[Any]])

.. _plugin_operation_dffml_print_output:

print_output
~~~~~~~~~~~~

*Official*

Print the output on stdout using python print()

Parameters
++++++++++
inputs : list
    A list of Inputs whose value is to be printed.

Examples
++++++++

The following example shows how to use print_output.

>>> dataflow = DataFlow.auto(print_output, GetSingle)
>>> inputs = [
...     Input(
...         value="print_output example",
...         definition=dataflow.definitions["DataToPrint"],
...         parents=None,)]
>>>
>>> async def main():
...     async for ctx, results in MemoryOrchestrator.run(dataflow, inputs):
...         print("String to be printed is 'print_output example'")
>>>
>>> asyncio.run(main())
print_output example
String to be printed is 'print_output example'

**Stage: processing**



**Inputs**

- data: DataToPrint(type: str)

.. _plugin_operation_dffml_feature_git:

dffml_feature_git
-----------------

.. code-block:: console

    pip install dffml-feature-git


.. _plugin_operation_dffml_feature_git_check_if_valid_git_repository_URL:

check_if_valid_git_repository_URL
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- URL: URL(type: string)

**Outputs**

- valid: valid_git_repository_URL(type: boolean)

.. _plugin_operation_dffml_feature_git_cleanup_git_repo:

cleanup_git_repo
~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: cleanup**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str

.. _plugin_operation_dffml_feature_git_clone_git_repo:

clone_git_repo
~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- URL: URL(type: string)

**Outputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str

**Conditions**

- valid_git_repository_URL: boolean

.. _plugin_operation_dffml_feature_git_count_authors:

count_authors
~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- author_lines: author_line_count(type: Dict[str, int])

**Outputs**

- authors: author_count(type: int)

.. _plugin_operation_dffml_feature_git_git_commits:

git_commits
~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str
- branch: git_branch(type: str)
- start_end: date_pair(type: List[date])

**Outputs**

- commits: commit_count(type: int)

.. _plugin_operation_dffml_feature_git_git_repo_author_lines_for_dates:

git_repo_author_lines_for_dates
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str
- branch: git_branch(type: str)
- start_end: date_pair(type: List[date])

**Outputs**

- author_lines: author_line_count(type: Dict[str, int])

.. _plugin_operation_dffml_feature_git_git_repo_checkout:

git_repo_checkout
~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str
- commit: git_commit(type: string)

**Outputs**

- repo: git_repository_checked_out(type: Dict[str, str])

  - URL: str
  - directory: str
  - commit: str

.. _plugin_operation_dffml_feature_git_git_repo_commit_from_date:

git_repo_commit_from_date
~~~~~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str
- branch: git_branch(type: str)
- date: date(type: string)

**Outputs**

- commit: git_commit(type: string)

.. _plugin_operation_dffml_feature_git_git_repo_default_branch:

git_repo_default_branch
~~~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str

**Outputs**

- branch: git_branch(type: str)

**Conditions**

- no_git_branch_given: boolean

.. _plugin_operation_dffml_feature_git_git_repo_release:

git_repo_release
~~~~~~~~~~~~~~~~

*Official*

Was there a release within this date range

**Stage: processing**



**Inputs**

- repo: git_repository(type: Dict[str, str])

  - URL: str
  - directory: str
- branch: git_branch(type: str)
- start_end: date_pair(type: List[date])

**Outputs**

- present: release_within_period(type: bool)

.. _plugin_operation_dffml_feature_git_lines_of_code_by_language:

lines_of_code_by_language
~~~~~~~~~~~~~~~~~~~~~~~~~

*Official*

This operation relys on ``tokei``. Here's how to install version 10.1.1,
check it's releases page to make sure you're installing the latest version.

On Linux

.. code-block:: console

    $ curl -sSL 'https://github.com/XAMPPRocky/tokei/releases/download/v10.1.1/tokei-v10.1.1-x86_64-apple-darwin.tar.gz' \
      | tar -xvz && \
      echo '22699e16e71f07ff805805d26ee86ecb9b1052d7879350f7eb9ed87beb0e6b84fbb512963d01b75cec8e80532e4ea29a tokei' | sha384sum -c - && \
      sudo mv tokei /usr/local/bin/

On OSX

.. code-block:: console

    $ curl -sSL 'https://github.com/XAMPPRocky/tokei/releases/download/v10.1.1/tokei-v10.1.1-x86_64-apple-darwin.tar.gz' \
      | tar -xvz && \
      echo '8c8a1d8d8dd4d8bef93dabf5d2f6e27023777f8553393e269765d7ece85e68837cba4374a2615d83f071dfae22ba40e2 tokei' | sha384sum -c - && \
      sudo mv tokei /usr/local/bin/

**Stage: processing**



**Inputs**

- repo: git_repository_checked_out(type: Dict[str, str])

  - URL: str
  - directory: str
  - commit: str

**Outputs**

- lines_by_language: lines_by_language_count(type: Dict[str, Dict[str, int]])

.. _plugin_operation_dffml_feature_git_lines_of_code_to_comments:

lines_of_code_to_comments
~~~~~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- langs: lines_by_language_count(type: Dict[str, Dict[str, int]])

**Outputs**

- code_to_comment_ratio: language_to_comment_ratio(type: int)

.. _plugin_operation_dffml_feature_git_quarters_back_to_date:

quarters_back_to_date
~~~~~~~~~~~~~~~~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- date: quarter_start_date(type: int)
- number: quarter(type: int)

**Outputs**

- date: date(type: string)
- start_end: date_pair(type: List[date])

.. _plugin_operation_dffml_feature_git_work:

work
~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- author_lines: author_line_count(type: Dict[str, int])

**Outputs**

- work: work_spread(type: int)

.. _plugin_operation_dffml_feature_auth:

dffml_feature_auth
------------------

.. code-block:: console

    pip install dffml-feature-auth


.. _plugin_operation_dffml_feature_auth_scrypt:

scrypt
~~~~~~

*Official*

No description

**Stage: processing**



**Inputs**

- password: UnhashedPassword(type: string)

**Outputs**

- password: ScryptPassword(type: string)